{
  "cells": [
    {
      "cell_type": "raw",
      "id": "db059ac8",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Senior Data Science Project\"\n",
        "format: html\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f4f024",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "from textwrap import wrap\n",
        "from tqdm import tqdm\n",
        "\n",
        "image_path = '/Users/scotttow123/Documents/BYUI/Senior Data Science Project/Images'\n",
        "caption_file = \"/Users/scotttow123/Documents/BYUI/Senior Data Science Project/captions.txt\"\n",
        "\n",
        "try:\n",
        "    data = pd.read_csv(caption_file)\n",
        "    print(\"Data loaded successfully\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {caption_file} was not found.\")\n",
        "    data = pd.DataFrame() \n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108bd87e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_image(path, img_size=224):\n",
        "    \"\"\"Reads and preprocesses an image.\"\"\"\n",
        "    try:\n",
        "        img = load_img(path, color_mode='rgb', target_size=(img_size, img_size))\n",
        "        img = img_to_array(img)\n",
        "        img = img / 255.0\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading image {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def display_images(temp_df, img_dir, num_images=9):\n",
        "    \"\"\"Displays a grid of images with their captions.\"\"\"\n",
        "    temp_df = temp_df.reset_index(drop=True)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        image_path = os.path.join(img_dir, temp_df.image[i])\n",
        "        \n",
        "        image = read_image(image_path)\n",
        "        if image is not None:\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"\\n\".join(wrap(temp_df.caption[i], 20)))\n",
        "        else:\n",
        "            plt.imshow(np.ones((224, 224, 3))) \n",
        "            plt.title(\"Image not found\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_images(data.sample(9), image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ff7273",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(img_path, img_size=224):\n",
        "    \"\"\"Loads and preprocesses an image for the VGG16 model.\"\"\"\n",
        "    img = load_img(img_path, target_size=(img_size, img_size))\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img) \n",
        "    return img\n",
        "\n",
        "def extract_features_batch(image_dir, model, img_size=224, batch_size=32):\n",
        "    \"\"\"Extract features from images using a pre-trained model in batches.\"\"\"\n",
        "    features = {}\n",
        "    image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir)]\n",
        "    \n",
        "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting features\"):\n",
        "        batch_paths = image_paths[i:i + batch_size]\n",
        "        batch_images = []\n",
        "\n",
        "        for img_path in batch_paths:\n",
        "            img = preprocess_image(img_path, img_size)\n",
        "            batch_images.append(img)\n",
        "\n",
        "        batch_images = np.array(batch_images)\n",
        "        batch_features = model.predict(batch_images, verbose=0)\n",
        "\n",
        "        for img_path, feature in zip(batch_paths, batch_features):\n",
        "            img_name = os.path.basename(img_path)\n",
        "            features[img_name] = feature.flatten()\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def display_images(temp_df, img_dir, num_images=9):\n",
        "    \"\"\"Displays a grid of images with their captions.\"\"\"\n",
        "    temp_df = temp_df.reset_index(drop=True)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        image_path = os.path.join(img_dir, temp_df.image[i])\n",
        "        image = preprocess_image(image_path, img_size=224) \n",
        "        plt.imshow(image / 255.0)  \n",
        "        plt.title(\"\\n\".join(wrap(temp_df.caption[i], 20)))\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display 9 random images with captions\n",
        "display_images(data.sample(9), image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f95f2ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_caption_stats(captions):\n",
        "    \"\"\"Displays some statistics about the captions.\"\"\"\n",
        "    caption_lengths = captions.apply(lambda x: len(x.split()))\n",
        "    print(f\"Total captions: {len(captions)}\")\n",
        "    print(f\"Average caption length: {caption_lengths.mean():.2f} words\")\n",
        "    print(f\"Max caption length: {caption_lengths.max()} words\")\n",
        "    print(f\"Min caption length: {caption_lengths.min()} words\")\n",
        "\n",
        "display_caption_stats(data['caption'])\n",
        "\n",
        "display_images(data.sample(9), image_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
